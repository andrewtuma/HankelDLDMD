{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy as sp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "import DLDMD as dl\n",
    "import LossDLDMD as lf\n",
    "import Data as dat\n",
    "import Training as tr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edmd(x, num_pred):\n",
    "    x = tf.transpose(x, perm=[0, 2, 1])\n",
    "    x_m = x[:, :, :-1]\n",
    "    x_p = x[:, :, 1:]\n",
    "    \n",
    "    S, U, V = tf.linalg.svd(x_m, compute_uv=True, full_matrices=False)\n",
    "    sm = np.max(S)\n",
    "    r = S.shape[-1]\n",
    "    Sri = tf.linalg.diag(1./S[:, :r])\n",
    "    Ur = U[:, :, :r]\n",
    "    Urh = tf.linalg.adjoint(Ur)\n",
    "    Vr = V[:, :, :r]\n",
    "    \n",
    "    kmat = x_p @ Vr @ Sri @ Urh\n",
    "    evals, evecs = tf.linalg.eig(kmat)\n",
    "    phim = tf.linalg.solve(evecs, tf.cast(x_m, dtype=tf.complex128))\n",
    "    x0 = phim[:, :, 0]\n",
    "    x0 = x0[:, :, tf.newaxis]\n",
    "    \n",
    "    pred = tf.TensorArray(tf.complex128, size=num_pred)\n",
    "    pred = pred.write(0, evecs @ x0)\n",
    "    evals_iter = tf.identity(evals)\n",
    "    for ii in range(num_pred):\n",
    "        tmp = evecs @ tf.linalg.diag(evals_iter) @ x0\n",
    "        pred = pred.write(ii, tmp)\n",
    "        evals_iter = evals_iter * evals\n",
    "    pred = tf.transpose(tf.squeeze(pred.stack()), perm=[1, 2, 0])\n",
    "    return phim, evals, evecs, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n",
      "Eager execution: True\n",
      "Num GPUs available: 0\n",
      "Training at precision: float64\n",
      "Training on device: /CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Figure parameters\n",
    "plot_save_path = './analysis_results/'\n",
    "font = {'family': 'DejaVu Sans', 'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fontsize = 18\n",
    "figsize = (15, 10)\n",
    "dpisave = 300\n",
    "\n",
    "# Initialize the compute device\n",
    "DEVICE = '/GPU:0'\n",
    "GPUS = tf.config.experimental.list_physical_devices('GPU')\n",
    "if GPUS:\n",
    "    try:\n",
    "        for gpu in GPUS:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    DEVICE = '/CPU:0'\n",
    "    \n",
    "tf.keras.backend.set_floatx('float64')  # !! Set precision for the entire model here\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Num GPUs available: {}\".format(len(GPUS)))\n",
    "print(\"Training at precision: {}\".format(tf.keras.backend.floatx()))\n",
    "print(\"Training on device: {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using precision: float64\n",
      "\n",
      "Test data shape: (10, 800, 2)\n",
      "{'sim_start': '2022-04-15-0024', 'experiment': 'pendulum', 'plot_path': './training_results/pendulum_2022-04-15-0024', 'model_path': './trained_models/pendulum_2022-04-15-0024', 'device': '/CPU:0', 'precision': 'float64', 'num_init_conds': 15000, 'num_train_init_conds': 10000, 'num_val_init_conds': 3000, 'num_test_init_conds': 2000, 'time_final': 20, 'delta_t': 0.05, 'num_time_steps': 401, 'num_pred_steps': 401, 'max_epochs': 100, 'save_every': 100, 'plot_every': 1, 'num_observables': 1, 'threshhold': 6, 'observation_dimension': 0, 'optimizer': 'adam', 'batch_size': 64, 'phys_dim': 2, 'latent_dim': 2, 'hidden_activation': <function relu at 0x7f914310ad40>, 'bias_initializer': <class 'keras.initializers.initializers_v2.Zeros'>, 'num_en_layers': 3, 'num_en_neurons': 128, 'kernel_init_enc': <keras.initializers.initializers_v2.TruncatedNormal object at 0x7f9142ee90d0>, 'kernel_init_dec': <keras.initializers.initializers_v2.TruncatedNormal object at 0x7f9142ee93d0>, 'ae_output_activation': <function linear at 0x7f914310f440>, 'a1': <tf.Tensor: shape=(), dtype=float64, numpy=1.0>, 'a2': <tf.Tensor: shape=(), dtype=float64, numpy=1.0>, 'a3': <tf.Tensor: shape=(), dtype=float64, numpy=1.0>, 'a4': <tf.Tensor: shape=(), dtype=float64, numpy=1e-14>, 'lr': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# SET THIS PATH (w/o file extension). Both '.pkl' and '.h5' files should have same name\n",
    "model_path = './trained_models/pendulum_2022-04-15-0024/epoch_100_loss_-2.33'\n",
    "hyp_params_path = model_path + '.pkl'\n",
    "weight_path = model_path + '.h5'\n",
    "\n",
    "# Load the hyper parameters\n",
    "hyp_params = pickle.load(open(hyp_params_path, 'rb'))\n",
    "\n",
    "# Set Tensorflow backend precision\n",
    "tf.keras.backend.set_floatx(hyp_params['precision'])\n",
    "print(\"Using precision: {}\\n\".format(tf.keras.backend.floatx()))\n",
    "\n",
    "# Create evenly spaced data\n",
    "double_time = hyp_params['time_final']*2\n",
    "num_steps = int(double_time / hyp_params['delta_t'])\n",
    "num_ic = 10\n",
    "x1 = np.linspace(-3.00001, 0.1, num_ic)\n",
    "x2 = np.zeros(num_ic)\n",
    "data_mat = np.zeros((num_ic, 2, num_steps), dtype=np.float64)\n",
    "for ii in range(num_ic):\n",
    "    data_mat[ii, :, 0] = np.array([x1[ii], x2[ii]], dtype=np.float64)\n",
    "    for jj in range(num_steps - 1):\n",
    "        data_mat[ii, :, jj+1] = dat.rk4(data_mat[ii, :, jj],\n",
    "                                        hyp_params['delta_t'],\n",
    "                                        dat.dyn_sys_pendulum)\n",
    "test_data = np.transpose(data_mat, [0, 2, 1])\n",
    "\n",
    "# Load evenly spaced rings for test trajectories\n",
    "# test_data = pickle.load(open('evenly_spaced_trajs.pkl', 'rb'))\n",
    "# test_data = tf.cast(test_data, dtype=hyp_params['precision'])\n",
    "print(\"Test data shape: {}\".format(test_data.shape))\n",
    "print(hyp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sim_start': '2022-04-15-0024', 'experiment': 'pendulum', 'plot_path': './training_results/pendulum_2022-04-15-0024', 'model_path': './trained_models/pendulum_2022-04-15-0024', 'device': '/CPU:0', 'precision': 'float64', 'num_init_conds': 15000, 'num_train_init_conds': 10000, 'num_val_init_conds': 3000, 'num_test_init_conds': 2000, 'time_final': 20, 'delta_t': 0.05, 'num_time_steps': 800, 'num_pred_steps': 401, 'max_epochs': 100, 'save_every': 100, 'plot_every': 1, 'num_observables': 1, 'threshhold': 6, 'observation_dimension': 0, 'optimizer': 'adam', 'batch_size': 10, 'phys_dim': 2, 'latent_dim': 2, 'hidden_activation': <function relu at 0x7f914310ad40>, 'bias_initializer': <class 'keras.initializers.initializers_v2.Zeros'>, 'num_en_layers': 3, 'num_en_neurons': 128, 'kernel_init_enc': <keras.initializers.initializers_v2.TruncatedNormal object at 0x7f9142ee90d0>, 'kernel_init_dec': <keras.initializers.initializers_v2.TruncatedNormal object at 0x7f9142ee93d0>, 'ae_output_activation': <function linear at 0x7f914310f440>, 'a1': <tf.Tensor: shape=(), dtype=float64, numpy=1.0>, 'a2': <tf.Tensor: shape=(), dtype=float64, numpy=1.0>, 'a3': <tf.Tensor: shape=(), dtype=float64, numpy=1.0>, 'a4': <tf.Tensor: shape=(), dtype=float64, numpy=1e-14>, 'lr': 1e-05, 'pretrain': False}\n",
      "Number of prediction steps:  800\n",
      "{'_self_setattr_tracking': True, '_is_model_for_instrumentation': True, '_instrumented_keras_api': True, '_instrumented_keras_layer_class': False, '_instrumented_keras_model_class': True, '_trainable': True, '_stateful': False, 'built': True, '_input_spec': None, '_build_input_shape': None, '_saved_model_inputs_spec': TensorSpec(shape=(10, 800, 2), dtype=tf.float64, name='input_1'), '_supports_masking': False, '_name': 'dldmd_1', '_activity_regularizer': None, '_trainable_weights': [], '_non_trainable_weights': [], '_updates': [], '_thread_local': <_thread._local object at 0x7f915119fb30>, '_callable_losses': [], '_losses': [], '_metrics': [], '_metrics_lock': <unlocked _thread.lock object at 0x7f9180be7960>, '_dtype_policy': <Policy \"float64\">, '_compute_dtype_object': tf.float64, '_autocast': True, '_self_tracked_trackables': [<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f914320b850>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f915117ce50>], '_inbound_nodes_value': [], '_outbound_nodes_value': [], '_expects_training_arg': False, '_default_training_arg': None, '_expects_mask_arg': False, '_dynamic': False, '_initial_weights': None, '_auto_track_sub_layers': True, '_preserve_input_structure_in_config': False, '_is_graph_network': False, 'inputs': None, 'outputs': None, 'input_names': None, 'output_names': None, 'stop_training': False, 'history': None, 'compiled_loss': None, 'compiled_metrics': None, '_compute_output_and_mask_jointly': False, '_is_compiled': False, 'optimizer': None, '_distribution_strategy': None, '_cluster_coordinator': None, '_run_eagerly': None, 'train_function': None, 'test_function': None, 'predict_function': None, '_compiled_trainable_state': <WeakKeyDictionary at 0x7f9142e58dd0>, '_training_state': None, '_trackable_saver': <tensorflow.python.training.tracking.util.TrackableSaver object at 0x7f914320bc10>, '_steps_per_execution': None, '_train_counter': <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>, '_test_counter': <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>, '_predict_counter': <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>, '_base_model_initialized': True, '_obj_reference_counts_dict': ObjectIdentityDictionary({<_ObjectIdentityWrapper wrapping 10>: 1, <_ObjectIdentityWrapper wrapping 2>: 2, <_ObjectIdentityWrapper wrapping 800>: 2, <_ObjectIdentityWrapper wrapping 3>: 1, <_ObjectIdentityWrapper wrapping 128>: 1, <_ObjectIdentityWrapper wrapping 0.05>: 1, <_ObjectIdentityWrapper wrapping 'float64'>: 1, <_ObjectIdentityWrapper wrapping 6>: 1, <_ObjectIdentityWrapper wrapping 0>: 1, <_ObjectIdentityWrapper wrapping (800, 2)>: 1, <_ObjectIdentityWrapper wrapping (None, 2)>: 1, <_ObjectIdentityWrapper wrapping tf.complex128>: 1, <_ObjectIdentityWrapper wrapping <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f914320b850>>: 1, <_ObjectIdentityWrapper wrapping <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f915117ce50>>: 1, <_ObjectIdentityWrapper wrapping 40>: 1, <_ObjectIdentityWrapper wrapping 90>: 1, <_ObjectIdentityWrapper wrapping 711>: 1}), 'batch_size': 10, 'phys_dim': 2, 'latent_dim': 2, 'num_time_steps': 800, 'num_en_layers': 3, 'num_neurons': 128, 'delta_t': 0.05, 'precision': 'float64', 'threshhold': 6, 'observation_dimension': 0, 'enc_input': (800, 2), 'dec_input': (None, 2), 'precision_complex': tf.complex128, '_self_unconditional_checkpoint_dependencies': [TrackableReference(name='encoder', ref=<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f914320b850>), TrackableReference(name='decoder', ref=<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f915117ce50>)], '_self_unconditional_dependency_names': {'encoder': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f914320b850>, 'decoder': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f915117ce50>}, '_self_unconditional_deferred_dependencies': {}, '_self_update_uid': -1, '_self_name_based_restores': set(), '_self_saveable_object_factories': {}, 'encoder': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f914320b850>, 'decoder': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f915117ce50>, 'num_pred_steps': 800, 'time_final': 40, 'num_observables': 90, 'window': 711}\n"
     ]
    }
   ],
   "source": [
    "# Fix hyper parameters for running the model on test data\n",
    "hyp_params['pretrain'] = False\n",
    "hyp_params['batch_size'] = test_data.shape[0]\n",
    "hyp_params['num_time_steps'] = test_data.shape[1]\n",
    "hyp_params['latent_dim'] = test_data.shape[2]\n",
    "hyp_params['phys_dim'] = test_data.shape[2]\n",
    "# hyp_params['num_observables'] = 70\n",
    "\n",
    "print(hyp_params)\n",
    "\n",
    "# Load the trained DLDMD model weights\n",
    "model = dl.DLDMD(hyp_params)\n",
    "model.num_pred_steps = model.num_time_steps\n",
    "model.time_final = int(model.num_time_steps*model.delta_t)\n",
    "model(test_data)\n",
    "model.load_weights(weight_path)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss = lf.LossDLDMD(hyp_params)\n",
    "print(\"Number of prediction steps: \", model.num_pred_steps)\n",
    "num_obsvs_opt = int(180/2)\n",
    "num_time_steps = int(hyp_params['num_time_steps'])\n",
    "model.num_observables = num_obsvs_opt\n",
    "model.window = num_time_steps - (num_obsvs_opt - 1)\n",
    "loss.num_observables = num_obsvs_opt\n",
    "loss.window = num_time_steps - (num_obsvs_opt - 1)\n",
    "\n",
    "print(vars(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hankel_dmd(Y):\n",
    "    Y = np.transpose(Y, [0, 2, 1])\n",
    "    print(\"shape of Y: \", np.shape(Y))\n",
    "    nobs = 90\n",
    "    winsize = model.num_time_steps - (nobs - 1)\n",
    "    # Perform DMD method.  Note, we need to be careful about how we break the concatenated Hankel matrix apart.\n",
    "\n",
    "    gm = tf.Variable(tf.zeros([nobs*hyp_params['phys_dim'], hyp_params['batch_size'] * (winsize - 1)], dtype=hyp_params['precision']))\n",
    "    gp = tf.Variable(tf.zeros([nobs*hyp_params['phys_dim'], hyp_params['batch_size'] * (winsize - 1)], dtype=hyp_params['precision']))\n",
    "\n",
    "    print(\"gm shape: \", gm.shape)\n",
    "    print(\"gp shape: \", gp.shape)\n",
    "    for jj in range(hyp_params['phys_dim']):\n",
    "        Yobserved = (tf.squeeze(Y[:, jj, :])).numpy()\n",
    "        for ll in range(hyp_params['batch_size']):\n",
    "            tseries = Yobserved[ll, :]\n",
    "            tcol = tseries[:nobs]\n",
    "            trow = tseries[(nobs - 1):]\n",
    "            hmat = np.flipud(sp.linalg.toeplitz(tcol[::-1], trow))\n",
    "\n",
    "            print(\"hmat shape: \", np.shape(hmat))\n",
    "            print(\"nobs: \", nobs)\n",
    "            print(\"winsize: \", winsize)\n",
    "            gm[jj*nobs:(jj+1)*nobs, ll * (winsize - 1):(ll + 1) * (winsize - 1)].assign(hmat[:, :-1])\n",
    "            gp[jj*nobs:(jj+1)*nobs, ll * (winsize - 1):(ll + 1) * (winsize - 1)].assign(hmat[:, 1:])\n",
    "\n",
    "    sig, U, V = tf.linalg.svd(gm, compute_uv=True, full_matrices=False)\n",
    "    sig_inv = tf.linalg.diag(1.0 / sig)\n",
    "    Uh = tf.linalg.adjoint(U)\n",
    "    gpV = gp @ V\n",
    "    A = gpV @ sig_inv @ Uh\n",
    "    evals, evecs = tf.linalg.eig(A)\n",
    "    phi = tf.linalg.solve(evecs, tf.cast(gm, dtype=tf.complex128))\n",
    "\n",
    "    normgp = tf.norm(gp, ord='fro', axis=[-2, -1])\n",
    "    normgpV = tf.norm(gpV, ord='fro', axis=[-2, -1])\n",
    "    dmdloss = tf.math.sqrt(normgp**2. - normgpV**2.)/tf.math.sqrt(tf.cast(hyp_params['batch_size']*(winsize-1), dtype=hyp_params['precision']))\n",
    "\n",
    "    # Build reconstruction\n",
    "    phiinit = phi[:, ::(winsize-1)]\n",
    "    initconds = tf.cast(tf.transpose(tf.squeeze(Y[:, :, 0])), dtype=tf.complex128)\n",
    "    sigp, Up, Vp = tf.linalg.svd(phiinit, compute_uv=True, full_matrices=False)\n",
    "    sigp_inv = tf.cast(tf.linalg.diag(1.0 / sigp), dtype=tf.complex128)\n",
    "    kmat = initconds @ Vp @ sigp_inv @ tf.linalg.adjoint(Up)\n",
    "    recon = tf.reshape(tf.transpose(tf.math.real(kmat @ phi)), [hyp_params['batch_size'], winsize-1, hyp_params['phys_dim']])\n",
    "    # comment out dmdloss from return\n",
    "    return recon, evals, evecs, phi, dmdloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the DLDMD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6605270\n",
      "Log10 Loss: -0.1801094\n"
     ]
    }
   ],
   "source": [
    "with tf.device(DEVICE):\n",
    "    [y, x_ae, x_adv, y_adv, weights, evals, evecs, phi, dmdloss] = model(test_data, training=False)\n",
    "    losses = loss([y, x_ae, x_adv, y_adv, weights, evals, evecs, phi, dmdloss], test_data)\n",
    "\n",
    "print(\"Loss: {loss:2.7f}\".format(loss=losses.numpy()))\n",
    "print(\"Log10 Loss: {loss:2.7f}\".format(loss=np.log10(losses.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Y:  (10, 2, 800)\n",
      "gm shape:  (180, 7100)\n",
      "gp shape:  (180, 7100)\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n",
      "hmat shape:  (90, 711)\n",
      "nobs:  90\n",
      "winsize:  711\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Eigen decomposition was not successful. The input might not be valid. [Op:Eig]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bf670a2cfd05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmdloss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhankel_dmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of xpred: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of xadv: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1eb711503677>\u001b[0m in \u001b[0;36mhankel_dmd\u001b[0;34m(Y)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mgpV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpV\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0msig_inv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mUh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36meig\u001b[0;34m(tensor, name)\u001b[0m\n\u001b[1;32m    407\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mout_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m   \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_linalg_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36meig\u001b[0;34m(input, Tout, compute_v, name)\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Eigen decomposition was not successful. The input might not be valid. [Op:Eig]"
     ]
    }
   ],
   "source": [
    "[x_pred, evals, evecs, phim, dmdloss] = hankel_dmd(test_data)\n",
    "print(\"shape of xpred: \", np.shape(x_pred))\n",
    "print(\"shape of xadv: \", np.shape(x_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run standard DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDMD on the unencoded data\n",
    "# [phim, evals, evecs, x_pred] = edmd(test_data, num_pred=test_data.shape[1])\n",
    "# x_pred = np.real(tf.transpose(x_pred, perm=[0, 2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fs = 20\n",
    "ts = 20\n",
    "lw = 2.0\n",
    "ms = 20.0\n",
    "figsize = (12, 12)\n",
    "skip = 1\n",
    "\n",
    "# DLHDMD reconstruction\n",
    "fig = plt.figure(1, figsize=figsize)\n",
    "for ii in range(0, test_data.shape[0], skip):\n",
    "    plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], color='red', linestyle='solid', lw=lw)\n",
    "    plt.plot(x_adv[ii, :, 0], x_adv[ii, :, 1], color='blue', linestyle='dotted', ms=ms)\n",
    "plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], color='red', linestyle='solid', lw=lw, label='Test data')\n",
    "plt.plot(x_adv[ii, 0, 0], x_adv[ii, 0, 1], color='blue', linestyle='dotted', ms=20*ms, label='DLHDMD')\n",
    "plt.xlabel(r'$x$', fontsize=fs)\n",
    "plt.ylabel(r'$\\dot{x}$', fontsize=fs)\n",
    "plt.legend(fontsize=fs, loc='upper right')\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=ts)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ts)\n",
    "# plt.savefig(\"reconstruction_pendulum.png\")\n",
    "\n",
    "# DMD reconstruction\n",
    "fig = plt.figure(2, figsize=figsize)\n",
    "for ii in range(0, test_data.shape[0], skip):\n",
    "    plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], color='red', linestyle='solid', lw=lw)\n",
    "    plt.plot(x_pred[ii, :, 0], x_pred[ii, :, 1], color='blue', linestyle='dotted', ms=ms)\n",
    "plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], color='red', linestyle='solid', lw=lw, label='Test data')\n",
    "plt.plot(x_pred[ii, 0, 0], x_pred[ii, 0, 1], color='blue', linestyle='dotted', ms=20*ms, label='Hankel DMD')\n",
    "plt.xlabel(r'$x$', fontsize=fs)\n",
    "plt.ylabel(r'$\\dot{x}$', fontsize=fs)\n",
    "plt.legend(fontsize=fs)\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=ts)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ts)\n",
    "\n",
    "# Plot the trajectories in phase space and latent space\n",
    "fig = plt.figure(3, figsize=figsize)\n",
    "for ii in range(0, test_data.shape[0], skip):\n",
    "    plt.plot(test_data[ii, :, 0], test_data[ii, :, 1], 'k', linestyle='solid', lw=lw)\n",
    "plt.xlabel(r'$x$', fontsize=fs)\n",
    "plt.ylabel(r'$\\dot{x}$', fontsize=fs)\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=ts)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ts)\n",
    "\n",
    "# Plot the trajectories in latent space\n",
    "fig = plt.figure(4, figsize=figsize)\n",
    "for ii in range(y_adv.shape[0]):\n",
    "    plt.plot(y[ii, :, 0], y[ii, :, 1], 'k', linestyle='solid', ms=ms)\n",
    "plt.xlabel(r'$\\tilde{x}_{1}$', fontsize=fs)\n",
    "plt.ylabel(r'$\\tilde{x}_{2}$', fontsize=fs)\n",
    "plt.axis('equal')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=ts)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=ts)\n",
    "# plt.savefig(\"latent_pendulum.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
